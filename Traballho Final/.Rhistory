buy.hold.equity = buy.hold$equity[dates] / as.double(buy.hold$equity[dates][1])
sma.cross.equity = sma.cross$equity[dates] / as.double(sma.cross$equity[dates][1])
chartSeries(buy.hold.equity, TA = c(addTA(sma.cross.equity, on=1, col='red')),
theme ='white', yrange = range(buy.hold.equity, sma.cross.equity) )
library(quantmod)
library(ggplot)
stocks <- c("AAPL", "MSFT", "ORCL", "GOOGL")
getSymbols(stocks, from = "2011-01-01", to = "2012-12-31")
install.packages("ggplot")
library(quantmod)
library(ggplot2)
stocks <- c("AAPL", "MSFT", "ORCL", "GOOGL")
getSymbols(stocks, from = "2011-01-01", to = "2012-12-31")
candleChart(AAPL, theme = Theme.black)
addADX()
candleChart(MSFT, theme = Theme.black)
addADX()
candleChart(ORCL, theme = Theme.black)
addADX()
candleChart(GOOGL, theme = Theme.black)
addADX()
Theme.black <- chartTheme("black")
Theme.black$up.border = "#FFFFFF00"
Theme.black$dn.border = "#FFFFFF00"
Theme.black$up.up.border = "#FFFFFF00"
Theme.black$up.dn.border = "#FFFFFF00"
Theme.black$dn.dn.border = "#FFFFFF00"
Theme.black$dn.up.border = "#FFFFFF00"
Theme.black$border = "#FFFFFF00"
candleChart(AAPL, theme = Theme.black)
addADX()
candleChart(MSFT, theme = Theme.black)
addADX()
candleChart(ORCL, theme = Theme.black)
addADX()
candleChart(GOOGL, theme = Theme.black)
addADX()
ADXAAPL <- as.data.frame(ADX(AAPL))
ADXMSFT <- as.data.frame(ADX(MSFT))
ADXORCL <- as.data.frame(ADX(ORCL))
ADXGOOGL <- as.data.frame(ADX(GOOGL))
AAPL.low <- subset(ADXAAPL, ADX < DIp & ADX < DIn)
MSFT.low <- subset(ADXMSFT, ADX < DIp & ADX < DIn)
ORCL.low <- subset(ADXORCL, ADX < DIp & ADX < DIn)
GOOGL.low <- subset(ADXGOOGL, ADX < DIp & ADX < DIn)
nrow(AAPL.low)
nrow(MSFT.low)
nrow(ORCL.low)
nrow(GOOGL.low)
install.packages("quantmod") #Install the quantmod library
install.packages("quantmod")
library("quantmod")  #Load the quantmod Library
stockData <- new.env() #Make a new environment for quantmod to store data in
startDate = as.Date("2008-01-13") #Specify period of time we are interested in
endDate = as.Date("2012-01-12")
tickers <- c("GOO","IBM") #Define the tickers we are interested in
endDate = as.Date("2014-11-21")
startDate = as.Date("2014-01-01") #Specify period of time we are interested in
tickers <- c("GOO","IBM") #Define the tickers we are interested in
getSymbols(tickers, env = stockData, src = "yahoo", from = startDate, to = endDate)
tickers <- c("GOOG","IBM") #Define the tickers we are interested in
getSymbols(tickers, env = stockData, src = "yahoo", from = startDate, to = endDate)
head(stockData$ARM)
stocks <- getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
head(stocks)
Cl(stockData$ARM)
chartSeries(stockData$ARM)
getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
head(IBM)
Cl(IBM)
Vol(IBM)
Vl(IBM)
chartSeries(IBM)
addBBands(n=50, sd=2)
head(IBM)
head(IBM.Close)
head(IBM$Close)
.
head(IBM)
?getSymbols
?Cl
chartSeries(IBM)
candleChart(IBM)
addBBands(n=50, sd=2)
startDate = as.Date("2014-05-01") #Specify period of time we are interested in
endDate = as.Date("2014-11-21")
tickers <- c("GOOG","IBM") #Define the tickers we are interested in
getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
head(IBM)
Cl(IBM)
candleChart(IBM)
addBBands(n=50, sd=2)
indicatorValuesBBands <- BBands(Cl(IBM),n=50, sd=2)
tickers <- c("GOOG","PETR4.SA") #Define the tickers we are interested in
getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
tickers <- c("GOOG","PETR4.SA")
getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
head(PETR4.SA)
head(PETR4.SA,5)
?getSymbols
Cl(GOOG)
candleChart(PETR4.SA)
addBBands(n=40, sd=2)
addADX(n = 11, maType="EMA", wilder=TRUE)
addBBands(n=20, sd=2)
candleChart(PETR4.SA)
addBBands(n=20, sd=2)
head(Cl(GOOG),5)
head(Cl(GOOG),-5)
head(Cl(GOOG),5)
addADX(n = 11, maType="EMA")
candleChart(PETR4.SA)
addBBands(n=20, sd=2)
addADX(n = 11, maType="EMA")
head(valorBollinger,5)
valorBollinger <- BBands(Cl(PETR4.SA),n=20, sd=2)
head(valorBollinger,5)
tail(valorBollinger,5)
library("quantmod")             #Carrega
startDate = as.Date("2014-05-01")
endDate = as.Date("2014-11-21")
tickers <- c("GOOG","PETR4.SA")
getSymbols(tickers, src = "yahoo", from = startDate, to = endDate)
head(PETR4.SA,5)
head(Cl(GOOG),5)
candleChart(PETR4.SA)
addSAR(accel = c(0.02, 0.2), col = "blue")
addSAR(accel = c(0.03, 0.2), col = "blue")
candleChart(PETR4.SA)
addSAR(accel = c(0.01, 0.2), col = "blue")
addSAR(accel = c(0.02, 0.2), col = "red")
addSAR(accel = c(0.03, 0.2), col = "green")
addSAR(accel = c(0.04, 0.2), col = "white")
?SAR
valorSAR <- SAR(Cl(PETR4.SA),accel = c(0.04, 0.2))
valorSAR <- SAR(PETR4.SA,accel = c(0.04, 0.2))
View(valorSAR)
candleChart(PETR4.SA)
addSAR(accel = c(0.02, 0.05), col = "white")
candleChart(PETR4.SA)
addSAR(accel = c(0.02, 0.05), col = "blue")
addSAR(accel = c(0.02, 0.1), col = "red")
addSAR(accel = c(0.02, 0.15), col = "green")
addSAR(accel = c(0.02, 0.2), col = "white")
candleChart(PETR4.SA)
addSAR(accel = c(0.01, 0.2), col = "blue")
addSAR(accel = c(0.02, 0.2), col = "red")
addSAR(accel = c(0.03, 0.2), col = "green")
addSAR(accel = c(0.04, 0.2), col = "white")
#Para criar um dataset de teste
t= 100
set.seed(2015)
transacoes <- data.frame(DVD = rbinom(t, 1, .7)
, GELADEIRA = rbinom(t, 1, .3)
, LIVRO = rbinom(t, 1, .9)
, CELULAR = rbinom(t, 1, .6)
)
regras <- apriori(as.matrix(transacoes)
,parameter=list(confidence=0.5,support=0.5))
# Para ordenar as regras
regras <- sort(regras,by="support")
# O inspect exibe as regras, neste caso ordenando pela confian√ßa
inspect(sort(head(regras,10),decreasing=T, by="confidence") )
#Para converter o conjunto de regras em um dataframe
regras_df = data.frame(
lhs = labels(lhs(regras))$elements, #lhs -> antecedente
rhs = labels(rhs(regras))$elements, #rhs -> consequente
regras@quality)
head(regras_df,10)
?apriori
library(arules)
t= 100
set.seed(2015)
transacoes <- data.frame(DVD = rbinom(t, 1, .7)
, GELADEIRA = rbinom(t, 1, .3)
, LIVRO = rbinom(t, 1, .9)
, CELULAR = rbinom(t, 1, .6)
)
regras <- apriori(as.matrix(transacoes)
,parameter=list(confidence=0.5,support=0.5))
# Para ordenar as regras
regras <- sort(regras,by="support")
# O inspect exibe as regras, neste caso ordenando pela confian√ßa
inspect(sort(head(regras,10),decreasing=T, by="confidence") )
#Para converter o conjunto de regras em um dataframe
regras_df = data.frame(
lhs = labels(lhs(regras))$elements, #lhs -> antecedente
rhs = labels(rhs(regras))$elements, #rhs -> consequente
regras@quality)
head(regras_df,10)
binom.test(60, 12, p =.5, alternative = ‚Äúone.sided‚Äù, ‚Äúless‚Äù, ‚Äúgreater‚Äù, conf.level = .95)
binom.test(60, 12, p =.5, conf.level = .95)
binom.test(60, 120, p =.5, conf.level = .95)
install.packages("FSelector")
load("C:/Users/Leandro/Google Drive/ARTEDOSDADOS/Kaggle/OTTO/otto_6_data.RData")
#Criando a vari·vel sumRow
test$sumRow <- 0
for (i in 1:dim(test)[1]){
test$sumRow[i] <- rowSums(test[2:94])[i]
print (i)
}
#Criando a vari·vel non_zero
test$non_zero <- 0
for (i in 1:dim(test)[1]){
test$non_zero[i] <- rowSums(test[2:94] != 0)[i]
print (i)
}
#Criando a vari·vel meanRow
test$meanRow <- 0
for (i in 1:dim(test)[1]){
test$meanRow[i] <- rowMeans(test[2:94])[i]
print (paste(i," meanRow"))
}
#Criando a vari·vel n_u_m
test$n_u_m <- 0
for (i in 1:dim(test)[1]){
test$n_u_m[i] <- rowMeans(test[2:94] < test$meanRow[i])[i]
print (paste(i," n_u_m"))
}
#InteraÁ„o entre sumRow e meanRow
test$sum_mean_Row <- 0
for (i in 1:dim(test)[1]){
test$sum_mean_Row[i] <- test$sumRow[i]*test$meanRow[i]
print (paste(i," sum_mean_Row"))
}
#InteraÁ„o entre meanRow e n_u_m
test$mean_num_Row <- 0
for (i in 1:dim(test)[1]){
test$mean_num_Row[i] <- test$n_u_m[i]*test$meanRow[i]
print (paste(i," mean_num_Row"))
}
save.image("C:\\Users\\Leandro\\Google Drive\\ARTEDOSDADOS\\Kaggle\\OTTO\\otto_6_data.RData")
#Criando a vari·vel meanRow
train2$meanRow <- 0
for (i in 1:dim(train2)[1]){
train2$meanRow[i] <- rowMeans(train2[1:93])[i]
print (paste(i," meanRow"))
}
#Criando a vari·vel n_u_m
train2$n_u_m <- 0
for (i in 1:dim(train2)[1]){
train2$n_u_m[i] <- rowMeans(train2[1:93] < train2$meanRow[i])[i]
print (paste(i," n_u_m"))
}
#InteraÁ„o entre sumRow e meanRow
train2$sum_mean_Row <- 0
for (i in 1:dim(train2)[1]){
train2$sum_mean_Row[i] <- train2$sumRow[i]*train2$meanRow[i]
print (paste(i," sum_mean_Row"))
}
#InteraÁ„o entre meanRow e n_u_m
train2$mean_num_Row <- 0
for (i in 1:dim(train2)[1]){
train2$mean_num_Row[i] <- train2$n_u_m[i]*train2$meanRow[i]
print (paste(i," mean_num_Row"))
}
load("C:/Users/Leandro/Google Drive/ARTEDOSDADOS/Kaggle/OTTO/otto_6_data.RData")
names(test)
names(train2)
summary(train2$n_u_m)
summary(test$n_u_m)
summary(sumRow$n_u_m)
summary(test$sumRow)
summary(test$non_zero)
summary(test$meanRow)
summary(test$n_u_m)
#Criando a vari·vel meanRow
test$meanRow <- 0
for (i in 1:dim(test)[1]){
test$meanRow[i] <- rowMeans(test[2:94])[i]
print (paste(i," meanRow"))
}
#Criando a vari·vel n_u_m
test$n_u_m <- 0
for (i in 1:dim(test)[1]){
test$n_u_m[i] <- rowMeans(test[2:94] < test$meanRow[i])[i]
print (paste(i," n_u_m"))
}
#InteraÁ„o entre sumRow e meanRow
test$sum_mean_Row <- 0
for (i in 1:dim(test)[1]){
test$sum_mean_Row[i] <- test$sumRow[i]*test$meanRow[i]
print (paste(i," sum_mean_Row"))
}
#InteraÁ„o entre meanRow e n_u_m
test$mean_num_Row <- 0
for (i in 1:dim(test)[1]){
test$mean_num_Row[i] <- test$n_u_m[i]*test$meanRow[i]
print (paste(i," mean_num_Row"))
}
save.image("C:\\Users\\Leandro\\Google Drive\\ARTEDOSDADOS\\Kaggle\\OTTO\\otto_6_data.RData")
names(train2)
train3 <- train2[,-94]
dim(train3)
x2 <- t(apply(train3, 1, combn, 2, sum))
colnames(x2) <- paste("comb_", combn(1:99, 2, paste), sep="")
train3 <- train2[,-94]
x2 <- t(apply(train3, 1, combn, 2, sum))
colnames(x2) <- paste("comb_", combn(1:99, 2, paste), sep="")
x <- cbind(train3, x2)
names(train2)
names(test)
ls()
rm(train3)
#Creates a random forest model using the target field as the response
#and all features as inputs
system.time({
strategy1 <- randomForest(as.factor(target) ~ .
, data=train2
, importance=TRUE, ntree=500)
})
#strategy1: OOB estimate of  error rate: x%
library(randomForest)
set.seed(2015)
#Creates a random forest model using the target field as the response
#and all features as inputs
system.time({
strategy1 <- randomForest(as.factor(target) ~ .
, data=train2
, importance=TRUE, ntree=500)
})
#strategy1: OOB estimate of  error rate: x%
q()
setwd("C:/Users/Leandro/Google Drive/FMU/TRABALHO_FINAL")
require(nnet)
base <- read.csv("banco_UMF.csv",header = TRUE, sep = ';')
head(base)
names(base)
dummies <- as.data.frame(
model.matrix(
~ job + marital + education + default + housing
+ loan + contact + month + poutcome + deposito -1 ,
data=base)
)
base2 <- cbind(base$age,base$balance,base$day,base$duration,
base$campaign,base$pdays,base$previous,dummies)
names(base2)
set.seed(611)
library(caret)
inTrain <- createDataPartition(y=base2$depositoyes,p = 0.70, list=FALSE)
training <- base2[inTrain,]
testing <- base2[-inTrain,]
dim(training); dim(testing)
x_training <- training[,-44]
y_training <- training$depositoyes
x_testing <- testing[,-44]
nn1<-nnet(x_training,y_training,size=10,linout=T,
rang = 0.1,decay = 5e-4, maxit = 1000)
plot.nnet(nn1,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.3,rel.rsc=5,
circle.cex=1,cex=1,
circle.col='brown')
source("./plot.net.R")
plot.nnet(nn1,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.3,rel.rsc=5,
circle.cex=1,cex=1,
circle.col='brown')
nn1<-nnet(x_training,y_training,size=10,linout=T,
rang = 0.1,decay = 5e-4, maxit = 10000)
prediction <- predict(nn1,x_testing)
evaluation <- cbind(prediction,testing$depositoyes)
write.csv2(evaluation,file='evaluation_2.csv')
head(base)
base <- read.csv("banco_UMF.csv",header = TRUE, sep = ';')
library(nnet)
source("./plot.net.R")
head(base)
names(base)
head(base)
names(base2)
dummies <- as.data.frame(
model.matrix(
~ job + marital + education + default + housing
+ loan + contact + month + poutcome + deposito -1 ,
data=base)
)
base2 <- cbind(base$age,base$balance,base$day,base$duration,
base$campaign,base$pdays,base$previous,dummies)
names(base2)
nn1<-nnet(x_training,y_training,size=10,linout=T,
rang = 0.1,decay = 5e-4, maxit = 10000)
prediction <- predict(nn1,x_testing)
evaluation <- cbind(prediction,testing$depositoyes)
write.csv2(evaluation,file='evaluation_2.csv')
set.seed(611)
library(caret)
inTrain <- createDataPartition(y=base2$depositoyes,p = 0.70, list=FALSE)
training <- base2[inTrain,]
testing <- base2[-inTrain,]
dim(training); dim(testing)
x_training <- training[,-44]
y_training <- training$depositoyes
x_testing <- testing[,-44]
nn1<-nnet(x_training,y_training,size=10,linout=T,
rang = 0.1,decay = 5e-4, maxit = 10000)
prediction <- predict(nn1,x_testing)
evaluation <- cbind(prediction,testing$depositoyes)
write.csv2(evaluation,file='evaluation_2.csv')
plot.nnet(nn1,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.3,rel.rsc=5,
circle.cex=1,cex=1,
circle.col='brown')
plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
circle.cex=1,cex=1,
circle.col='brown')
prediction > 0.7
(prediction > 0.7) + 1
(prediction > 0.7) + 0
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
nn1<-nnet(x_training,y_training,size=40,linout=T,
rang = 0.1,decay = 5e-4, maxit = 1000)
prediction <- predict(nn1,x_testing)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
nn1<-nnet(x_training,y_training,size=5,linout=T,
rang = 0.1,decay = 5e-4, maxit = 1000)
prediction <- predict(nn1,x_testing)
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
inTrain <- createDataPartition(y=base2$depositoyes,p = 0.60, list=FALSE)
training <- base2[inTrain,]
testing <- base2[-inTrain,]
dim(training); dim(testing)
x_training <- training[,-44]
y_training <- training$depositoyes
x_testing <- testing[,-44]
nn1<-nnet(x_training,y_training,size=5,linout=T,
rang = 0.1,decay = 5e-4, maxit = 1000)
prediction <- predict(nn1,x_testing)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
set.seed(611)
inTrain <- createDataPartition(y=base2$depositoyes,p = 0.70, list=FALSE)
training <- base2[inTrain,]
testing <- base2[-inTrain,]
dim(training); dim(testing)
x_training <- training[,-44]
y_training <- training$depositoyes
x_testing <- testing[,-44]
nn1<-nnet(x_training,y_training,size=5,linout=T,
rang = 0.1,decay = 5e-2, maxit = 1000)
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
prediction <- (prediction > 0.7) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.5) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.3) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.1) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
prediction <- (prediction > 0.1) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.3) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.5) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.2) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.3) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.3) + 0
table(testing$depositoyes,prediction)
summary(prediction)
prediction <- predict(nn1,x_testing)
summary(prediction)
#evaluation <- cbind(prediction,testing$depositoyes)
#write.csv2(evaluation,file='evaluation_2.csv')
#plot.nnet(nn1,pos.col='blue',neg.col='red',alpha.val=0.3,rel.rsc=5,
#          circle.cex=1,cex=1,
#         circle.col='brown')
prediction <- (prediction > 0.15) + 0
table(testing$depositoyes,prediction)
prediction <- (prediction > 0.3) + 0
table(testing$depositoyes,prediction)
prediction <- predict(nn1,x_testing)
summary(prediction)
prediction2 <- (prediction > 2*mean(prediction) + 0
table(testing$depositoyes,prediction)
table(testing$depositoyes,prediction2)
prediction2 <- (prediction > 2*mean(prediction) + 0
)
prediction2 <- (prediction > 2*mean(prediction)) + 0
table(testing$depositoyes,prediction2)
